import math as m # temporary fix to undefined variable "m" error
from random import seed
from random import random
from math import exp

def start_network(main_input: int, hidden_neur: int, output_neur: int):

    """
        This function initializes the neural network to be trained

            parameter (main_input): int
                Specifies number of inputs to feed the network
            
            parameter (hidden_neur): int
                Specifies the number of neurons in the hidden layer

            parameter (output_neur): int
                Specifies the number of neurons in the output layer

            Code reference: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/
    """

    # network list
    network = []

    # PLEASE NOTE: +1 is added to include the bias to the neuron
    """
        Below generates the hidden layer(s)
        > It is created by randomly generating the weights and biases for the input channels for
            the number of neurons in the hidden layer
    """
    hidden_layer = [{'weights':[random() for i in range(main_input + 1)]} for i in range(hidden_neur)]
    network.append(hidden_layer)

    """
        Below generates the output layer(s)
        > It is created by randomly generating the weights and biases for the channels fed to the 
            number of neurons in the output layer
    """
    output_layer = [{'weights':[random() for i in range(hidden_neur + 1)]} for i in range(output_neur)]
    network.append(output_layer)

    return network # return the layer information

i_count = int(input('Input Count: '))
h_count = int(input('Hidden Neuron Count: '))
o_count = int(input('Output Neuron Count: '))

seed(1) # generate the same random numbers every time code is run
get_the_network = start_network(i_count, h_count, o_count)

for layers in get_the_network:
    print(layers)

# PROPAGATION
def activate_neur(weights, inputs):
    """
        This function generates the activation value that a neuron will have which will determine
        the neurons output

        It replicates that of a linear regression function
        > neuron activation value = (neuron weight * input value) + bias

        parameter (weights): float
            Specifies the weight of each neuron from the "start_network" function
        
        parameter (inputs): float
            Specifies the value from the input to be fed to a neuron
    """
    activation = weights[-1] # assumes the generated BIAS is going to be at the end of the list of weights
    for i in range(len(weights)-1): # adds the bias to the product of the weight and input value
        activation += weights[i] * inputs[i]
    return activation

def transfer_func(activation):
    """
        This function generates the transfer function to transfer the output of the neuron to the next

        The activation function being used here is Sigmoid

        paremeter (activation): float
            Attains the activation values from the "activate_neur" function
    """
    sigmoid_func = 1 / 1 + exp(-activation)
    return sigmoid_func 

def forward_propagation(network, row):
    """
        This function propagates signals through the neural network layers to arrive at an output
        
        parameter (network): list
            Attains the neural network
        
        parameter (row): list
            Attains a row of data from a data set
    """
    get_inputs = row
    for layer in network: # loops through each layer generated by the network
        new_inputs = [] # makes a list of inputs for each layer looped
        for neuron in layer: # loops through each neuron in the layer
            activation = activate_neur(neuron['weights'], get_inputs) # send the weights and inputs from the neural network to the activation function
            neuron['output'] = transfer_func(activation) # return the calculated output from the transfer function
            new_inputs.append(neuron['output']) # add the data to the new input list
        inputs = new_inputs # changes from initial inputs to the new ones
    return inputs

random_input = [1, 0, None]
output_vals = forward_propagation(get_the_network, random_input)
